Android Photos App Project
Matthew Loaces
Sean Dong
How We Used AI Assistance
In developing our Android Photo App, we uesd AI assistance in a structured and methodical way, as outlined in the project requirements. Below is a detailed explanation of how we incorporated AI into our development process.
Our Approach
We approached AI assistance as a supplementary tool rather than a complete solution generator. Instead of "vibe coding" (asking the AI to build the entire app at once), we broke down the project into functional components and used AI to help with specific parts while maintaining control over the overall architecture and integration.
Specific AI Interactions
Project Structure Planning
Prompt: "Given the requirements for an Android Photos app port, what would be a good project structure to follow? We need to implement album management, photo display, tagging, and search functionality."
Outcome: The AI provided suggestions for package organization and class hierarchy, which we modified to fit our specific implementation needs.
Model Classes Development
Prompt: "How would you implement the Photo, Album, and Tag model classes for our Android port of the Photos app, given the JavaFX implementation we've already completed?"
Outcome: The AI provided draft implementations that we heavily customized to fit our specific data management approach.
UI Layout Creation
Prompts:
"Can you suggest an XML layout for the main activity that displays a list of albums?"
"What would a good layout for displaying photos in a grid look like?"
"How should we structure the photo detail view to show the image and its tags?"
Outcome: We received basic layout suggestions which we significantly modified to improve the user experience and match our application flow.
Controller Logic Assistance
Prompts:
"How can we implement the search functionality with tag type-value pairs and support for conjunction/disjunction?"
"What's the best way to implement tag auto-completion in Android?"
Outcome: AI provided algorithmic approaches and code snippets that we integrated into our controllers, with necessary modifications to handle edge cases.
Debugging Help
Prompts: Various debugging questions when we encountered specific issues
Outcome: AI helped identify potential solutions to bugs, which we then implemented and tested.
Components We Wrote Ourselves
We wrote substantial portions of the codebase ourselves, including:
All of the data serialization and persistence logic
The majority of the activity lifecycle management code
Custom adapters for displaying albums and photos
The slideshow implementation
The integration between different components
Error handling and validation
Performance optimizations
Components Generated by AI
AI assistance was primarily used for:
Initial draft of model classes (which we heavily modified)
Basic UI layout structures (which we enhanced and styled)
Algorithmic approaches for search functionality
Suggestions for handling Android permissions and file access
Integration Process
We integrated the AI-assisted components by:
Reviewing and understanding all generated code
Modifying it to match our architectural decisions
Ensuring consistent error handling across components
Testing each component individually before integration
Refactoring for code quality and maintainability
Ensuring the components work together cohesively
Conclusion
AI assistance was valuable for accelerating development and providing implementation approaches, but the final application architecture, integration, and many component implementations were primarily our own work. The AI served as a coding partner that helped with specific challenges while we maintained oversight of the overall development process.
